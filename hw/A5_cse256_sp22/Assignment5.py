# -*- coding: utf-8 -*-
"""Assignment 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KG4RQBkV5uWhH2K6zzVvIUlPMYsiB24V
"""

from __future__ import division
import re, json, pickle, copy
from collections import defaultdict, Counter


def basedir():
  return "/content/drive/MyDrive/Colab Notebooks/CSE256/A5_cse256_sp22/"

"""
Evaluate a set of test alignments versus the gold set. 
"""

class ParseError(Exception):
  def __init__(self, value):
    self.value = value
    
  def __str__(self):
    return self.value

class FScore:
  "Compute F1-Score based on gold set and test set."

  def __init__(self):
    self.gold = 0
    self.test = 0
    self.correct = 0

  def increment(self, gold_set, test_set):
    "Add examples from sets."
    self.gold += len(gold_set)
    self.test += len(test_set)
    self.correct += len(gold_set & test_set)

  def fscore(self): 
    pr = self.precision() + self.recall()
    if pr == 0: return 0.0
    return (2 * self.precision() * self.recall()) / pr

  def precision(self): 
    if self.test == 0: return 0.0
    return self.correct / self.test

  def recall(self): 
    if self.gold == 0: return 0.0
    return self.correct / self.gold    

  @staticmethod
  def output_header():
    "Output a scoring header."
    print ("%10s  %10s  %10s  %10s   %10s"%(
      "Type", "Total", "Precision", "Recall", "F1-Score"))
    print ("===============================================================")

  def output_row(self, name):
    "Output a scoring row."
    print ("%10s        %4d     %0.3f        %0.3f        %0.3f"%(
      name, self.gold, self.precision(), self.recall(), self.fscore()))

class CorpusAlignment:
  "Read in the alignment."
  def __init__(self, handle):
    self.all_align = set()
    self.sents_align = {}

    for l in handle:
      t = l.strip().split()
      if len(t) != 3: 
        raise ParseError("Alignment must have three columns. %s"%l)
      try:
        sent = int(t[0])
        align = (int(t[1]), int(t[2]))
        self.all_align.add((sent, align))
      except:
        raise ParseError("Alignment line must be integers. %s"%l)

  @staticmethod
  def compute_fscore(align1, align2):
    fscore = FScore()
    fscore.increment(align1.all_align, align2.all_align)
    return fscore

def main(gold_alignment, test_alignment):
  align1 = CorpusAlignment(gold_alignment)
  align2 = CorpusAlignment(test_alignment)
  fscore = CorpusAlignment.compute_fscore(align1, align2)
  FScore.output_header()
  fscore.output_row("total")
  
def eval_alignment(key_file, output_file):
  """
  Usage: python eval_alignment.py [key_file] [output_file]
      Evalute the accuracy of a output trees compared to a key file.\n
  """
  if key_file[-4:] != ".key":
    print("First argument should end in '.key'.")
    return
  main(open(basedir() + key_file), open(basedir() + output_file))

# Prepare data
def readFile(filename):
  sentences = []
  with open(basedir() + filename) as f:
    for line in f:
      sentences.append(line.strip().split(" "))
  
  return sentences

corpusEN = readFile("corpus.en")
corpusES = readFile("corpus.es")
devEN = readFile("dev.en")
devES = readFile("dev.es")

# Examinate Data
for i in range(3):
  print("corpus en:", corpusEN[i])
  print("corpus es:", corpusES[i])
  print("------------------------")
  print("dev en:", devEN[i])
  print("dev es:", devES[i])
  print("------------------------")

### IBM 1 model
NULL_WORD = "*"

class IBM_Model_One():
  def __init__(self, en_lines, es_lines):
    assert len(en_lines) == len(es_lines)
    print("Number of line check passed, init...")
    self.t_table = defaultdict(float)
    self.n_e_list = defaultdict(set)
    self.delta = defaultdict(float)
    self.en_lines = copy.deepcopy(en_lines)
    self.es_lines = copy.deepcopy(es_lines)
    self.reset_expected()
    self.init()

  def reset_expected(self):
    print("Reset Expected Count Map...")
    self.en_count = defaultdict(float)
    self.es_count = defaultdict(float)
    self.en_es_count = defaultdict(float)

  def init(self, init_t_table=True):
    for idx in range(len(self.en_lines)):
      # add NULL word into english side
      self.en_lines[idx].insert(0, NULL_WORD)

      for en in self.en_lines[idx]:
        self.en_count[en] = 0
        for es in self.es_lines[idx]:
          self.n_e_list[en].add(es)
    
    for line in self.es_lines:
      # Collect additional data
      for es in line:
        self.es_count[es] = 0

    # Senity Check
    print("Checking number of NULL word and unique word count: ", len(self.n_e_list[NULL_WORD]), len(self.es_count.keys()))
    assert len(self.n_e_list[NULL_WORD]) == len(self.es_count.keys())
    print("passed")

    # init t(f|e)  
    if init_t_table:
      print("Init T Table...")
      for en in self.en_count.keys():
        for es in self.n_e_list[en]:
          self.t_table[(en, es)] = 1 / len(self.n_e_list[en])

  def calculate_delta(self, k, en_line, i, es):
    total = 0
    for en in en_line:
      total += self.t_table[(en, es)]
    for j, en in enumerate(en_line):
      self.delta[(k, i, j)] = self.t_table[(en, es)] / total


  def EM_train(self):
    # Reset Expected count when start training
    self.reset_expected()
    
    print("Gathering Expected Count...")
    for k in range(len(self.en_lines)):
      en_line = self.en_lines[k]
      es_line = self.es_lines[k]
      for i, es in enumerate(es_line):
        self.calculate_delta(k, en_line, i, es)

        for j, en in enumerate(en_line):
          self.en_es_count[(en, es)] += self.delta[(k, i, j)]
          self.en_count[en] += self.delta[(k, i, j)]
    
    self.t_revision()
    
    print("EM Train finished.")

  def t_revision(self):
    # After each iteration, revise T
    print("Revising Translation Parameter...")
    for pair in self.t_table.keys():
        self.t_table[pair] = self.en_es_count[pair] / self.en_count[pair[0]]


  def save(self, file_path):
    with open(basedir() + file_path, "wb") as model:
      pickle.dump(self.__dict__, model, 2)
    print("Model Saved!")

  def read(self, pickle_file):
    with open(basedir() + pickle_file, "rb") as model:
      self.__dict__.update(pickle.load(model))
    print("Model Readed")


  def find_alignment(self, es, en_line):
    start_t = 0
    start_idx = None
    for idx, en in enumerate(en_line):
      pair = (en, es)
      if pair in self.t_table:
        t = self.t_table[pair] # Warning: read key will add key to the map, test before read
        if t > start_t:
          start_t = t
          start_idx = idx

    return start_idx


  def get_alignments(self, dev_en_lines, dev_es_lines):
    en_len = len(dev_en_lines)
    assert en_len == len(dev_es_lines)

    res = []
    for idx in range(en_len):
      # No NULL in alignment
      for i, es in enumerate(dev_es_lines[idx]):
        en_index = self.find_alignment(es, dev_en_lines[idx])
        if en_index != None:
          res.append((idx + 1, en_index + 1, i + 1))
    
    res.sort()
    
    return res

def write_alignments(res, file_path):
  with open(basedir() + file_path, "w") as f:
    for i in res:
      f.write("{} {} {}\n".format(*i))

### IBM 1 Training start
ibm_one = IBM_Model_One(corpusEN, corpusES)
ibm_one_alignment_file = "ibm_one_dev_alignment.key."
num_of_iteration = 5

for i in range(num_of_iteration):
  ibm_one.EM_train()
  partial_result = ibm_one_alignment_file + str(i + 1)
  res = ibm_one.get_alignments(devEN, devES)
  write_alignments(res, partial_result)
  print("-----------------")
  print("Iteration {} Result: ".format(i + 1))
  eval_alignment("dev.key", partial_result)
  print("-----------------")
  print()

print("{} Iteration finished!".format(num_of_iteration))
ibm_one_t_table = ibm_one.t_table
ibm_one.save("ibm_one.model")

### IBM Model 2

class IBM_Model_Two(IBM_Model_One):
  def __init__(self, en_lines, es_lines, t_table=None):
    self.q_table = defaultdict(float)
    self.q_count = defaultdict(float)
    super().__init__(en_lines, es_lines)
    if t_table != None:
      print("Requested Replace with external T Table of Size: ", len(t_table.keys()))
      self.t_table = copy.deepcopy(t_table) 

  def init(self):
    super().init(init_t_table=False)

    for k in range(len(self.en_lines)):
      en_line = self.en_lines[k]
      es_line = self.es_lines[k]
      l, m = len(en_line) - 1, len(es_line)
      for i, en in enumerate(es_line):
        for j, es in enumerate(en_line):
          # Alignment should be 1 for normal word, and NULL will always be 0
          # Trained section we loop thru all, but when testing, rule out NULL_WORD for alignment
          self.q_table[(j, i + 1, l, m)] = 1 / (l + 1)

  def calculate_delta(self, k, en_line, es_line, i):
    """
    i -> es_index
    """

    total = 0
    l, m = len(en_line) - 1, len(es_line)
    es = es_line[i]
    for j, en in enumerate(en_line):
      total += self.q_table[(j, i + 1, l, m)] * self.t_table[(en, es)]

    for j, en in enumerate(en_line):
      self.delta[(k, i + 1, j)] = (self.q_table[(j, i + 1, l, m)] * self.t_table[(en, es)]) / total

  def reset_expected(self):
    super().reset_expected()
    print("Reset Q Count Map...")
    self.sentence_length_count = defaultdict(float)
    self.q_count = defaultdict(float)

  def EM_train(self):
    self.reset_expected()

    """
      i -> f index
      j -> e index
      l -> e length, en_length
      m -> f length, es_length
    """

    print("Gathering Expected Count...")
    for k in range(len(self.en_lines)):
      en_line = self.en_lines[k]
      es_line = self.es_lines[k]
      l, m = len(en_line) - 1, len(es_line)

      for i, es in enumerate(es_line):
        self.calculate_delta(k, en_line, es_line, i)
        for j, en in enumerate(en_line):
          alignment = (j, i + 1, l, m)
          delta_alignment = (k, i + 1, j)
          diff = self.delta[delta_alignment]
          self.en_es_count[(en, es)] += diff
          self.en_count[en] += diff
          self.q_count[alignment] += diff
          self.sentence_length_count[alignment[1:]] += diff

    self.t_revision()
    
    print("Revising Distortion Parameter...")
    for pair in self.q_table.keys():
      self.q_table[pair] = self.q_count[pair] / self.sentence_length_count[pair[1:]]
    
    print("EM Train finished.")

  def find_alignment(self, en_line, es_line, i):
    l, m = len(en_line), len(es_line)
    es = es_line[i]

    start_p = 0
    start_idx = None

    for j, en in enumerate(en_line):
      qpair = (j + 1, i + 1, l, m)
      tpair = (en, es)
      if qpair in self.q_table and tpair in self.t_table:
        p = self.q_table[qpair] * self.t_table[tpair]
        if p > start_p:
          start_p = p
          start_idx = j

    return start_idx

  def get_alignments(self, dev_en_lines, dev_es_lines):
    en_len = len(dev_en_lines)
    assert en_len == len(dev_es_lines)

    res = []
    for k in range(en_len):
      for i, es in enumerate(dev_es_lines[k]):
        en_index = self.find_alignment(dev_en_lines[k], dev_es_lines[k], i)
        if en_index != None:
          res.append((k + 1, en_index + 1, i + 1))
    
    res.sort()
    
    return res

### IBM 2 Model Train Start
ibm_two = IBM_Model_Two(corpusEN, corpusES, ibm_one_t_table)
ibm_two_alignment_file = "ibm_two_dev_alignment.key."

for i in range(num_of_iteration):
  ibm_two.EM_train()
  partial_result = ibm_two_alignment_file + str(i + 1)
  res = ibm_two.get_alignments(devEN, devES)
  write_alignments(res, partial_result)
  print("-----------------")
  print("Iteration {} Result: ".format(i + 1))
  eval_alignment("dev.key", partial_result)
  print("-----------------")
  print()

print("{} Iteration finished!".format(num_of_iteration))
ibm_two.save("ibm_two.model")