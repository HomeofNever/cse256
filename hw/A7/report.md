# Assignment 7: Societal & Ethical Implications of Language Technologies

## Part 1. The Game (1 Point)

### Q1 

> Which NLP task is described by the author as a game of guessing the missing word?

It is for text generation task that train the model predicting the most possible word for the given context.

## Part 2: Opportunities and Challenges (4.5 Points)

### Q2 

> According to the author, what kind of jobs could be lost in the future because of software like GPT-3? Name three such jobs (1.5 Points). (*Opinion*) Which of the three jobs is the least likely to be replaced by GPT-3-like models anytime soon, and why? (0.5 Point)

- Journalist
- Customer Service
- Programmer/Coder

I believe that programming related problem may not be able to be replaced soon since coding evolves more logic and innovation during the process and its correctness it hard to be verify even for now. However, in general for all low-level, duplicate job in any fields listed above could be benefits from the model.

### Q3 

> According to the author, what are some specific criticisms that have been made against GPT-3 like models? Give three criticisms (1.5 Points).

- The software is capable only of blind mimicry — that it’s imitating the syntactic patterns of human language but is incapable of generating its own ideas or making complex decisions
- GPT-3 will forever remain compromised by the biases and propaganda and misinformation in the data it has been trained on, meaning that using it for anything more than parlor tricks will always be irresponsible
- It lacks common-sense knowledge about the world — the basic building blocks of relationships among objects, or their common applications — that human intelligence relies upon

### Q4 

> Why is it a societal problem if language models are simply “stochastic parrots” (1 Point)

It would not actually have its own idea to identify and self-heal from the toxicity of the wider Internet. The flaw in the data are kept and replayed, which is irresponsible if used in production.

## Part 3: Open AI Remedies (1 Point)

### Q5 

> According to the article, roughly, a fifth of Open AI is focused on “safety” and “alignment”. What are some specific things they are doing to “align the technology with humanity’s interests”. Give two examples (1 Point).

- It blocks any use of its software "to influence the political process or to be used for campaigning purposes."
- OpenAI’s software license explicitly forbids anyone to use their tools to "determine eligibility for credit, employment, housing or similar essential services."

## Part 4: Intelligence or Lack of (4 Points)

### Q6

> From what you have learned in the course and/or the Johnson article, what arguments can be made to support the thesis that “higher-level understanding is emerging, thanks to the deep layers of the neural net”. Make two points. You can give specific applications/datasets/evaluations as examples or make more abstract arguments. (2 Points).

- Users may give GPT-3 direct instruction instead of only expending on a sample of text, and with the exact same input, the model is able to generate unique responses
- According to Google, not one of the sentences in the Calvino essay has ever been written before. Each sentence appears to be a unique text string, custom-built for the occasion by the model.

> From what you have learned in the course and/or the Johnson article, what arguments can be made to support the thesis that “the program by definition can’t get to true understanding simply by playing ”guess the missing word” all day”. Make two points. You can give specific applications/datasets/evaluations as examples or make more abstract arguments (2 Points).

- In December 2021, DeepMind announced that its L.L.M. Gopher scored results on the RACE-h benchmark — a data set with exam questions comparable to those in the reading sections of the SAT. At the same time, L.L.M.s still perform poorly in logical and mathematical reasoning
- L.L.M.s are not conscious — there’s no internal "theater of the mind" where the software experiences thinking in the way sentient organisms like humans do

## Part 5: Regulation (2 Points)

### Q7

> (*Opinion*) Discuss your own thoughts with regard to the two questions at the end of the quote above (2 Points).

This technology will eventually come no matter how people try to push it back. The tech companies surely have the motivation and the resources to do it, while I believe law enforcement is the only barrier to stop these technology to go bad. It should shape the outcome and guide companies to push this technology on the right track, like bias test before production, etc.

## Part 6: “Resisting the Urge to be Impressed” (Bonus)

### Q8 

> Provide three specific arguments against the Johnson article as pointed out in the critique piece in Professor Emily Bender (1.5 Bonus Points)

- Problem is not necessary on AI itself, which is not given appropriate value
- It is not necessary that that AI should be built outside the megacorps or by a third-party. Regulation should empower worker and ordinary people to defense themselves.
- When machine is getting higher score on standardize test, it is not necessary the machine is actually functioning the same way as human, nor it is the desire way doing so. 